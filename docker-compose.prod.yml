# Production Docker Compose Configuration
# Usage: docker-compose -f docker-compose.prod.yml up -d
#
# ⚠️ SECURITY: Database and Redis ports are NOT exposed in production
# They are only accessible via internal Docker network

services:
  # PostgreSQL Database (Production)
  postgres:
    image: postgres:16-alpine
    container_name: boilerplate-db-prod
    environment:
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_DB: ${DB_NAME}
    # ❌ NO ports exposed in production (security best practice)
    # Database is only accessible via internal network
    # For external access, use SSH tunnel or VPN
    # ports:
    #   - "5432:5432"
    volumes:
      - postgres_data_prod:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER}"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: always
    networks:
      - boilerplate-network-prod
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '2'
        reservations:
          memory: 512M
          cpus: '1'

  # Redis Cache (Production)
  redis:
    image: redis:7-alpine
    container_name: boilerplate-redis-prod
    # ❌ NO ports exposed in production (security best practice)
    # Redis is only accessible via internal network
    # ports:
    #   - "6379:6379"
    volumes:
      - redis_data_prod:/data
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: always
    networks:
      - boilerplate-network-prod
    # Security & Performance configuration
    command: >
      redis-server
      --requirepass ${REDIS_PASSWORD}
      --maxmemory 512mb
      --maxmemory-policy allkeys-lru
      --appendonly yes
      --save 60 1000
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '1'
        reservations:
          memory: 256M
          cpus: '0.5'

  # Fastify Backend (Production) - Instance 1
  # Multiple instances for high availability and load balancing
  backend-1:
    build:
      context: .
      dockerfile: apps/backend/Dockerfile
    container_name: boilerplate-backend-1
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      NODE_ENV: production
      PORT: 3001
      # Database connection via internal network (postgres:5432, not localhost)
      DATABASE_URL: postgresql://${DB_USER}:${DB_PASSWORD}@postgres:5432/${DB_NAME}
      # Redis connection via internal network with password and TLS
      # Note: For production, use rediss:// with TLS certificates
      # Development/staging: redis:// is acceptable on internal Docker network
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379
      # Production with TLS: REDIS_URL: rediss://:${REDIS_PASSWORD}@redis:6379

      # JWT Secrets (MUST be 32+ chars in production)
      JWT_SECRET: ${JWT_SECRET}
      JWT_REFRESH_SECRET: ${JWT_REFRESH_SECRET}

      # Frontend URL
      FRONTEND_URL: ${FRONTEND_URL}

      # Email Service (Resend)
      RESEND_API_KEY: ${RESEND_API_KEY:-}
      EMAIL_FROM: ${EMAIL_FROM:-noreply@votreapp.com}

      # Stripe
      STRIPE_SECRET_KEY: ${STRIPE_SECRET_KEY}
      STRIPE_PUBLISHABLE_KEY: ${STRIPE_PUBLISHABLE_KEY}
      STRIPE_WEBHOOK_SECRET: ${STRIPE_WEBHOOK_SECRET}

      # Monitoring
      SENTRY_DSN: ${SENTRY_DSN:-}

      # Backup Configuration
      BACKUP_RETENTION_DAYS: ${BACKUP_RETENTION_DAYS:-7}
      BACKUP_CRON_SCHEDULE: ${BACKUP_CRON_SCHEDULE:-0 2 * * *}

      # AWS S3 Backups (Optional)
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID:-}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY:-}
      AWS_REGION: ${AWS_REGION:-us-east-1}
      AWS_S3_BACKUP_BUCKET: ${AWS_S3_BACKUP_BUCKET:-}

      # Cleanup Configuration
      CLEANUP_BATCH_SIZE: ${CLEANUP_BATCH_SIZE:-1000}
      CLEANUP_PAUSE_MS: ${CLEANUP_PAUSE_MS:-100}
    restart: always
    networks:
      - boilerplate-network-prod
    expose:
      - "3001"
    # Run migrations on startup
    command: sh -c "npx prisma migrate deploy && npm start"
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '1'
        reservations:
          memory: 256M
          cpus: '0.5'

  # Fastify Backend (Production) - Instance 2
  backend-2:
    build:
      context: .
      dockerfile: apps/backend/Dockerfile
    container_name: boilerplate-backend-2
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      NODE_ENV: production
      PORT: 3001
      DATABASE_URL: postgresql://${DB_USER}:${DB_PASSWORD}@postgres:5432/${DB_NAME}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379
      JWT_SECRET: ${JWT_SECRET}
      JWT_REFRESH_SECRET: ${JWT_REFRESH_SECRET}
      FRONTEND_URL: ${FRONTEND_URL}
      RESEND_API_KEY: ${RESEND_API_KEY:-}
      EMAIL_FROM: ${EMAIL_FROM:-noreply@votreapp.com}
      STRIPE_SECRET_KEY: ${STRIPE_SECRET_KEY}
      STRIPE_PUBLISHABLE_KEY: ${STRIPE_PUBLISHABLE_KEY}
      STRIPE_WEBHOOK_SECRET: ${STRIPE_WEBHOOK_SECRET}
      SENTRY_DSN: ${SENTRY_DSN:-}
      BACKUP_RETENTION_DAYS: ${BACKUP_RETENTION_DAYS:-7}
      BACKUP_CRON_SCHEDULE: ${BACKUP_CRON_SCHEDULE:-0 2 * * *}
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID:-}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY:-}
      AWS_REGION: ${AWS_REGION:-us-east-1}
      AWS_S3_BACKUP_BUCKET: ${AWS_S3_BACKUP_BUCKET:-}
      CLEANUP_BATCH_SIZE: ${CLEANUP_BATCH_SIZE:-1000}
      CLEANUP_PAUSE_MS: ${CLEANUP_PAUSE_MS:-100}
    restart: always
    networks:
      - boilerplate-network-prod
    expose:
      - "3001"
    # Skip migrations on second instance (already run by backend-1)
    command: npm start
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '1'
        reservations:
          memory: 256M
          cpus: '0.5'

  # Next.js Frontend (Production)
  frontend:
    build:
      context: .
      dockerfile: apps/frontend/Dockerfile
      args:
        NEXT_PUBLIC_API_URL: ${NEXT_PUBLIC_API_URL}
    container_name: boilerplate-frontend-prod
    depends_on:
      - backend-1
      - backend-2
    environment:
      NEXT_PUBLIC_API_URL: ${NEXT_PUBLIC_API_URL}
    restart: always
    networks:
      - boilerplate-network-prod
    expose:
      - "3000"
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '1'
        reservations:
          memory: 256M
          cpus: '0.5'

  # Nginx Load Balancer & Reverse Proxy (Production)
  # Distributes traffic across 2 backend instances with health checks
  nginx:
    image: nginx:alpine
    container_name: boilerplate-nginx
    depends_on:
      - backend-1
      - backend-2
      - frontend
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.prod.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - nginx_logs:/var/log/nginx
    restart: always
    networks:
      - boilerplate-network-prod
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.5'
        reservations:
          memory: 128M
          cpus: '0.25'

networks:
  boilerplate-network-prod:
    driver: bridge

volumes:
  postgres_data_prod:
    driver: local
  redis_data_prod:
    driver: local
  nginx_logs:
    driver: local
